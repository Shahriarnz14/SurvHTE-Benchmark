{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de623e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c573dd",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b50bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_files = [\n",
    "    \"../real_data/twin.csv\",\n",
    "    \"../real_data/twin30.csv\",\n",
    "    \"../real_data/twin180.csv\",\n",
    "]\n",
    "\n",
    "experiment_setups = {}\n",
    "\n",
    "for path in store_files:\n",
    "    base_name = os.path.splitext(os.path.basename(path))[0]  # e.g. twin\n",
    "    scenario_dict = {}\n",
    "    for scenario in range(1, 2): # only one scenario per HIV data\n",
    "        try:\n",
    "            result = pd.read_csv(path)\n",
    "            if result is not None:\n",
    "                scenario_dict[f\"scenario_{scenario}\"] = result\n",
    "        except Exception as e:\n",
    "            # Log or ignore as needed\n",
    "            continue\n",
    "    experiment_setups[base_name] = scenario_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c30fcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>observed_time</th>\n",
       "      <th>event</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>W</th>\n",
       "      <th>true_cate</th>\n",
       "      <th>anemia</th>\n",
       "      <th>...</th>\n",
       "      <th>resstatb_4</th>\n",
       "      <th>mpcb_1</th>\n",
       "      <th>mpcb_2</th>\n",
       "      <th>mpcb_3</th>\n",
       "      <th>mpcb_4</th>\n",
       "      <th>mpcb_5</th>\n",
       "      <th>mpcb_6</th>\n",
       "      <th>mpcb_7</th>\n",
       "      <th>mpcb_8</th>\n",
       "      <th>mpcb_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>195.954330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20.717881</td>\n",
       "      <td>1</td>\n",
       "      <td>-178</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55.907504</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>55.907504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.168915</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>4.168915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1</td>\n",
       "      <td>-175</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11395</th>\n",
       "      <td>11395</td>\n",
       "      <td>15.080879</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>15.080879</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11396</th>\n",
       "      <td>11396</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>233.524041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11397</th>\n",
       "      <td>11397</td>\n",
       "      <td>117.663304</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>117.663304</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11398</th>\n",
       "      <td>11398</td>\n",
       "      <td>30.417666</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>180</td>\n",
       "      <td>38</td>\n",
       "      <td>30.417666</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11399</th>\n",
       "      <td>11399</td>\n",
       "      <td>59.124944</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>59.124944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11400 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx  observed_time  event   T0   T1    T           C  W  true_cate  \\\n",
       "0          0     180.000000      1  180  180  180  195.954330  0          0   \n",
       "1          1       2.000000      1  180    2    2   20.717881  1       -178   \n",
       "2          2      55.907504      0  180  180  180   55.907504  0          0   \n",
       "3          3       4.168915      0  180  180  180    4.168915  1          0   \n",
       "4          4       0.000042      0  180    5    5    0.000042  1       -175   \n",
       "...      ...            ...    ...  ...  ...  ...         ... ..        ...   \n",
       "11395  11395      15.080879      0  180  180  180   15.080879  1          0   \n",
       "11396  11396     180.000000      1  180  180  180  233.524041  0          0   \n",
       "11397  11397     117.663304      0  180  180  180  117.663304  1          0   \n",
       "11398  11398      30.417666      0   38  180   38   30.417666  0        142   \n",
       "11399  11399      59.124944      0  180  180  180   59.124944  0          0   \n",
       "\n",
       "       anemia  ...  resstatb_4  mpcb_1  mpcb_2  mpcb_3  mpcb_4  mpcb_5  \\\n",
       "0           0  ...           0       0       0       1       0       0   \n",
       "1           0  ...           0       0       0       0       0       0   \n",
       "2           0  ...           0       0       1       0       0       0   \n",
       "3           0  ...           0       0       1       0       0       0   \n",
       "4           0  ...           0       0       0       1       0       0   \n",
       "...       ...  ...         ...     ...     ...     ...     ...     ...   \n",
       "11395       0  ...           0       0       1       0       0       0   \n",
       "11396       0  ...           0       1       0       0       0       0   \n",
       "11397       1  ...           0       0       1       0       0       0   \n",
       "11398       0  ...           0       0       1       0       0       0   \n",
       "11399       1  ...           0       0       0       0       0       0   \n",
       "\n",
       "       mpcb_6  mpcb_7  mpcb_8  mpcb_9  \n",
       "0           0       0       0       0  \n",
       "1           0       0       0       0  \n",
       "2           0       0       0       0  \n",
       "3           0       0       0       0  \n",
       "4           0       0       0       0  \n",
       "...       ...     ...     ...     ...  \n",
       "11395       0       0       0       0  \n",
       "11396       0       0       0       0  \n",
       "11397       0       0       0       0  \n",
       "11398       0       0       0       0  \n",
       "11399       0       1       0       0  \n",
       "\n",
       "[11400 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_setups['twin180']['scenario_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c729fcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>random_idx0</th>\n",
       "      <th>random_idx1</th>\n",
       "      <th>random_idx2</th>\n",
       "      <th>random_idx3</th>\n",
       "      <th>random_idx4</th>\n",
       "      <th>random_idx5</th>\n",
       "      <th>random_idx6</th>\n",
       "      <th>random_idx7</th>\n",
       "      <th>random_idx8</th>\n",
       "      <th>random_idx9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4673</td>\n",
       "      <td>8193</td>\n",
       "      <td>2015</td>\n",
       "      <td>1620</td>\n",
       "      <td>11124</td>\n",
       "      <td>2792</td>\n",
       "      <td>2763</td>\n",
       "      <td>3687</td>\n",
       "      <td>4907</td>\n",
       "      <td>9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8847</td>\n",
       "      <td>4943</td>\n",
       "      <td>7700</td>\n",
       "      <td>4045</td>\n",
       "      <td>5430</td>\n",
       "      <td>5809</td>\n",
       "      <td>2248</td>\n",
       "      <td>6564</td>\n",
       "      <td>10370</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5554</td>\n",
       "      <td>1711</td>\n",
       "      <td>1268</td>\n",
       "      <td>1411</td>\n",
       "      <td>11188</td>\n",
       "      <td>10742</td>\n",
       "      <td>6328</td>\n",
       "      <td>1891</td>\n",
       "      <td>1937</td>\n",
       "      <td>9248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9208</td>\n",
       "      <td>2687</td>\n",
       "      <td>11191</td>\n",
       "      <td>2758</td>\n",
       "      <td>8578</td>\n",
       "      <td>10274</td>\n",
       "      <td>10448</td>\n",
       "      <td>2396</td>\n",
       "      <td>5476</td>\n",
       "      <td>4819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>9283</td>\n",
       "      <td>9089</td>\n",
       "      <td>878</td>\n",
       "      <td>3289</td>\n",
       "      <td>3300</td>\n",
       "      <td>9654</td>\n",
       "      <td>3714</td>\n",
       "      <td>7741</td>\n",
       "      <td>2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11395</th>\n",
       "      <td>11395</td>\n",
       "      <td>4892</td>\n",
       "      <td>3659</td>\n",
       "      <td>6350</td>\n",
       "      <td>6294</td>\n",
       "      <td>1565</td>\n",
       "      <td>10981</td>\n",
       "      <td>3671</td>\n",
       "      <td>10546</td>\n",
       "      <td>1215</td>\n",
       "      <td>8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11396</th>\n",
       "      <td>11396</td>\n",
       "      <td>8346</td>\n",
       "      <td>8007</td>\n",
       "      <td>5825</td>\n",
       "      <td>11</td>\n",
       "      <td>7334</td>\n",
       "      <td>8926</td>\n",
       "      <td>6832</td>\n",
       "      <td>5698</td>\n",
       "      <td>6831</td>\n",
       "      <td>8875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11397</th>\n",
       "      <td>11397</td>\n",
       "      <td>4426</td>\n",
       "      <td>6524</td>\n",
       "      <td>2822</td>\n",
       "      <td>10916</td>\n",
       "      <td>6607</td>\n",
       "      <td>8329</td>\n",
       "      <td>4656</td>\n",
       "      <td>5140</td>\n",
       "      <td>4654</td>\n",
       "      <td>10104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11398</th>\n",
       "      <td>11398</td>\n",
       "      <td>3360</td>\n",
       "      <td>3408</td>\n",
       "      <td>5652</td>\n",
       "      <td>10744</td>\n",
       "      <td>8170</td>\n",
       "      <td>4830</td>\n",
       "      <td>4917</td>\n",
       "      <td>3441</td>\n",
       "      <td>10438</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11399</th>\n",
       "      <td>11399</td>\n",
       "      <td>1899</td>\n",
       "      <td>4826</td>\n",
       "      <td>1018</td>\n",
       "      <td>11157</td>\n",
       "      <td>10617</td>\n",
       "      <td>6452</td>\n",
       "      <td>7948</td>\n",
       "      <td>6025</td>\n",
       "      <td>321</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx  random_idx0  random_idx1  random_idx2  random_idx3  random_idx4  \\\n",
       "0          0         4673         8193         2015         1620        11124   \n",
       "1          1         8847         4943         7700         4045         5430   \n",
       "2          2         5554         1711         1268         1411        11188   \n",
       "3          3         9208         2687        11191         2758         8578   \n",
       "4          4          337         9283         9089          878         3289   \n",
       "...      ...          ...          ...          ...          ...          ...   \n",
       "11395  11395         4892         3659         6350         6294         1565   \n",
       "11396  11396         8346         8007         5825           11         7334   \n",
       "11397  11397         4426         6524         2822        10916         6607   \n",
       "11398  11398         3360         3408         5652        10744         8170   \n",
       "11399  11399         1899         4826         1018        11157        10617   \n",
       "\n",
       "       random_idx5  random_idx6  random_idx7  random_idx8  random_idx9  \n",
       "0             2792         2763         3687         4907         9965  \n",
       "1             5809         2248         6564        10370          386  \n",
       "2            10742         6328         1891         1937         9248  \n",
       "3            10274        10448         2396         5476         4819  \n",
       "4             3300         9654         3714         7741         2289  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "11395        10981         3671        10546         1215         8200  \n",
       "11396         8926         6832         5698         6831         8875  \n",
       "11397         8329         4656         5140         4654        10104  \n",
       "11398         4830         4917         3441        10438          948  \n",
       "11399         6452         7948         6025          321          288  \n",
       "\n",
       "[11400 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_repeat_setups = [pd.read_csv(f'../real_data/idx_split_twin.csv')]\n",
    "experiment_repeat_setups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba626474",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_ATE = {('twin', 'scenario_1'): 5.038157894736842,\n",
    "            ('twin30', 'scenario_1'): 0.32824561403508773,\n",
    "            ('twin180', 'scenario_1'): 2.260438596491228}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5d8d8",
   "metadata": {},
   "source": [
    "### EXPERIMENT CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b60d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_REPEATS_TO_INCLUDE = 10\n",
    "TRAIN_SIZE = 0.5\n",
    "VAL_SIZE = 0.25\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "horizon = 365\n",
    "min_node_size = 18\n",
    "train_size = 0.5\n",
    "\n",
    "output_pickle_path = f\"../results/real_data/models_causal_survival/causal_survival_forest/\"\n",
    "output_pickle_path += f\"twin_causal_survival_forest_repeats_{NUM_REPEATS_TO_INCLUDE}.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31730f57",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d36764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of \"notebooks\" to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from models_causal_survival.causal_survival_forest import CausalSurvivalForestGRF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ec0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_twin_data_split(dataset_df, X_cols, W_col, cate_base_col, experiment_repeat_setup):\n",
    "    split_results = {}\n",
    "    length = len(experiment_repeat_setup)\n",
    "    \n",
    "    for rand_idx in range(NUM_REPEATS_TO_INCLUDE):\n",
    "        y_cols = ['observed_time', 'event']\n",
    "        # take the first half of the dataset for training and the second half for testing\n",
    "        train_ids = experiment_repeat_setup[f'random_idx{rand_idx}'][:int(length*TRAIN_SIZE)].values\n",
    "        test_ids =  experiment_repeat_setup[f'random_idx{rand_idx}'][int(length*TRAIN_SIZE):].values # this includes both validation and test data\n",
    "        \n",
    "        train_df = dataset_df[dataset_df['idx'].isin(train_ids)]\n",
    "        test_df = dataset_df[dataset_df['idx'].isin(test_ids)]\n",
    "\n",
    "        X_train = train_df[X_cols].to_numpy()\n",
    "        W_train = train_df[W_col].to_numpy().flatten()\n",
    "        Y_train = train_df[y_cols].to_numpy()\n",
    "\n",
    "        X_test = test_df[X_cols].to_numpy()\n",
    "        W_test = test_df[W_col].to_numpy().flatten()\n",
    "        Y_test = test_df[y_cols].to_numpy()\n",
    "\n",
    "        cate_test_true = test_df[cate_base_col].to_numpy()\n",
    "\n",
    "        split_results[rand_idx] = (X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true)\n",
    "\n",
    "    return split_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a3a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary_cols = ['anemia', 'cardiac', 'lung', 'diabetes', 'herpes', 'hydra',\n",
    "       'hemo', 'chyper', 'phyper', 'eclamp', 'incervix', 'pre4000', 'preterm',\n",
    "       'renal', 'rh', 'uterine', 'othermr', \n",
    "       'gestat', 'dmage', 'dmeduc', 'dmar', 'nprevist', 'adequacy']\n",
    "X_num_cols = ['dtotord', 'cigar', 'drink', 'wtgain']\n",
    "X_ohe_cols = ['pldel_2', 'pldel_3', 'pldel_4', 'pldel_5', 'resstatb_2', 'resstatb_3', 'resstatb_4', \n",
    "              'mpcb_1', 'mpcb_2', 'mpcb_3', 'mpcb_4', 'mpcb_5', 'mpcb_6', 'mpcb_7', 'mpcb_8', 'mpcb_9']\n",
    "\n",
    "y_cols = ['observed_time_month', 'effect_non_censor'] # ['time', 'cid']\n",
    "\n",
    "X_cols = X_binary_cols + X_num_cols + X_ohe_cols\n",
    "W_col = ['W']\n",
    "cate_true_col = 'true_cate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d351e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure times grid: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  60  90 120 150 180\n",
      " 210 240 270 300 330 360]\n",
      "Output results path: ../results/real_data/models_causal_survival/causal_survival_forest/twin_causal_survival_forest_repeats_10.pkl\n",
      "Pickle file already exists. Loading from ../results/real_data/models_causal_survival/causal_survival_forest/twin_causal_survival_forest_repeats_10.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Setups:   0%|          | 0/2 [00:00<?, ?it/s]R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.03059 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.03682 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.03854 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.03366 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.0388 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.02721 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.03667 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.02501 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.0415 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "R[write to console]: Warning in (function (X, Y, W, D, W.hat = NULL, target = c(\"RMST\", \"survival.probability\"),  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  Estimated censoring probabilities go as low as: 0.03596 - an identifying assumption is that there exists a fixed positive constant M such that the probability of observing an event past the maximum follow-up time  is at least M (i.e. P(T > horizon | X) > M). This warning appears when M is less than 0.05, at which point causal survival forest can not be expected to deliver reliable estimates.\n",
      "\n",
      "Experiment Setups: 100%|██████████| 2/2 [02:18<00:00, 69.17s/it]\n"
     ]
    }
   ],
   "source": [
    "failure_times_grid_size = 200\n",
    "# failure_times_grid: non-uniform discretization – \n",
    "# i.e. resolution of days in the first 30 days and months after the first 30 days\n",
    "failure_times_grid = np.concatenate([np.arange(0, 30), np.arange(30, 365, 30)]) # every day for 1 month, then every month\n",
    "print(\"Failure times grid:\", failure_times_grid)\n",
    "horizon = 365\n",
    "min_node_size = 18\n",
    "\n",
    "print(\"Output results path:\", output_pickle_path)\n",
    "\n",
    "if os.path.exists(output_pickle_path):\n",
    "    print(f\"Pickle file already exists. Loading from {output_pickle_path}...\")\n",
    "    with open(output_pickle_path, \"rb\") as f:\n",
    "        results_dict = pickle.load(f)\n",
    "else:\n",
    "    results_dict = {}\n",
    "\n",
    "for setup_name, setup_dict in tqdm(experiment_setups.items(), desc=\"Experiment Setups\"):\n",
    "    if setup_name == \"twin30\":\n",
    "        horizon = 30\n",
    "    elif setup_name == \"twin180\":\n",
    "        horizon = 180\n",
    "    else:\n",
    "        pass\n",
    "    if setup_name in results_dict:\n",
    "        print(f\"Skipping setup {setup_name} as it already exists in results.\")\n",
    "        continue\n",
    "    results_dict[setup_name] = {}\n",
    "    experiment_repeat_setup = experiment_repeat_setups[0]\n",
    "\n",
    "    for scenario_key in tqdm(setup_dict, desc=f\"{setup_name} Scenarios\", leave=False):\n",
    "        dataset_df = setup_dict[scenario_key]\n",
    "        split_dict = prepare_twin_data_split(dataset_df, X_cols, W_col, cate_true_col, \n",
    "                                             experiment_repeat_setup)\n",
    "\n",
    "        # Initialize results dictionary for this setup and scenario\n",
    "        results_dict[setup_name][scenario_key] = {}\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        for rand_idx in range(NUM_REPEATS_TO_INCLUDE):\n",
    "            X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true = split_dict[rand_idx]\n",
    "            # take first half of test set as validation set\n",
    "            X_val, W_val, Y_val = X_test[:int(len(dataset_df)*VAL_SIZE)], W_test[:int(len(dataset_df)*VAL_SIZE)], Y_test[:int(len(dataset_df)*VAL_SIZE)]\n",
    "            cate_val_true = cate_test_true[:int(len(dataset_df)*VAL_SIZE)]\n",
    "            X_test, W_test, Y_test = X_test[int(len(dataset_df)*VAL_SIZE):], W_test[int(len(dataset_df)*VAL_SIZE):], Y_test[int(len(dataset_df)*VAL_SIZE):]\n",
    "            cate_test_true = cate_test_true[int(len(dataset_df)*VAL_SIZE):]\n",
    "\n",
    "            # Store placeholder for later population\n",
    "            results_dict[setup_name][scenario_key][rand_idx] = {}\n",
    "\n",
    "            # Train the model\n",
    "            csf = CausalSurvivalForestGRF(failure_times_grid_size=failure_times_grid_size, \n",
    "                                          horizon=horizon, min_node_size=min_node_size, seed=2025+rand_idx)\n",
    "            csf.fit(X_train, W_train, Y_train, failure_times_grid=failure_times_grid)\n",
    "\n",
    "            ate_true =     TRUE_ATE.get((setup_name, scenario_key), cate_test_true.mean())\n",
    "            ate_true_val = TRUE_ATE.get((setup_name, scenario_key), cate_val_true.mean())\n",
    "\n",
    "            # Predict CATE\n",
    "            # cate_test_pred = csf.predict_cate(X_test, W_test)\n",
    "            mse_test, cate_test_pred, ate_test_pred = csf.evaluate(X_test, cate_test_true, W_test)\n",
    "            mse_val, cate_val_pred, ate_val_pred = csf.evaluate(X_val, cate_val_true, W_val)\n",
    "\n",
    "            # Save results\n",
    "            results_dict[setup_name][scenario_key][rand_idx] = {\n",
    "                \"cate_true\": cate_test_true,\n",
    "                \"cate_pred\": cate_test_pred,\n",
    "                \"ate_true\": ate_true,\n",
    "                \"ate_pred\": ate_test_pred,\n",
    "                \"cate_mse\": mse_test,\n",
    "                \"ate_bias\": ate_test_pred - ate_true,\n",
    "                # val set:\n",
    "                \"cate_true_val\": cate_val_true,\n",
    "                \"cate_pred\": cate_val_pred,\n",
    "                \"ate_true_val\": ate_true_val,\n",
    "                \"ate_pred_val\": ate_val_pred,\n",
    "                \"cate_mse_val\": mse_val,\n",
    "                \"ate_bias_val\": ate_val_pred - ate_true_val,\n",
    "\n",
    "            }\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Save results to the setup dictionary\n",
    "        results_dict[setup_name][scenario_key][\"average\"] = {\n",
    "            \"mean_cate_mse\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"cate_mse\"]\n",
    "                                      for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_cate_mse\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"cate_mse\"]\n",
    "                                    for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"mean_ate_pred\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"ate_pred\"]\n",
    "                                      for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_ate_pred\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"ate_pred\"]\n",
    "                                    for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"mean_ate_true\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"ate_true\"]\n",
    "                                      for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_ate_true\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"ate_true\"]\n",
    "                                    for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"mean_ate_bias\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"ate_bias\"]\n",
    "                                      for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_ate_bias\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"ate_bias\"]\n",
    "                                    for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "\n",
    "            \"mean_cate_mse_val\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"cate_mse_val\"]\n",
    "                                            for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_cate_mse_val\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"cate_mse_val\"]\n",
    "                                        for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"mean_ate_pred_val\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"ate_pred_val\"]\n",
    "                                          for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_ate_pred_val\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"ate_pred_val\"]\n",
    "                                        for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"mean_ate_true_val\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"ate_true_val\"]\n",
    "                                          for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_ate_true_val\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"ate_true_val\"]\n",
    "                                        for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"mean_ate_bias_val\": np.mean([results_dict[setup_name][scenario_key][rand_idx][\"ate_bias_val\"]\n",
    "                                          for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "            \"std_ate_bias_val\": np.std([results_dict[setup_name][scenario_key][rand_idx][\"ate_bias_val\"]\n",
    "                                        for rand_idx in range(NUM_REPEATS_TO_INCLUDE)]),\n",
    "\n",
    "\n",
    "            \"runtime\": (end_time - start_time) / len(range(NUM_REPEATS_TO_INCLUDE))\n",
    "        }\n",
    "\n",
    "        # Save progress to disk\n",
    "        with open(output_pickle_path, \"wb\") as f:\n",
    "            pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6874816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_experiment_results(results_dict):\n",
    "    records = []\n",
    "\n",
    "    for setup_name, setup_dict in results_dict.items():\n",
    "        for scenario_key in setup_dict:\n",
    "            avg_result = setup_dict[scenario_key].get(\"average\", {})\n",
    "            mean_mse = avg_result.get(\"mean_cate_mse\", np.nan)\n",
    "            std_mse = avg_result.get(\"std_cate_mse\", np.nan)\n",
    "            mean_ate_pred = avg_result.get(\"mean_ate_pred\", np.nan)\n",
    "            std_ate_pred = avg_result.get(\"std_ate_pred\", np.nan)\n",
    "            mean_ate_true = avg_result.get(\"mean_ate_true\", np.nan)\n",
    "            std_ate_true = avg_result.get(\"std_ate_true\", np.nan)\n",
    "            mean_ate_bias = avg_result.get(\"mean_ate_bias\", np.nan)\n",
    "            std_ate_bias = avg_result.get(\"std_ate_bias\", np.nan)\n",
    "\n",
    "            mean_ate_pred_val = avg_result.get(\"mean_ate_pred_val\", np.nan)\n",
    "            std_ate_pred_val = avg_result.get(\"std_ate_pred_val\", np.nan)\n",
    "            mean_ate_true_val = avg_result.get(\"mean_ate_true_val\", np.nan)\n",
    "            std_ate_true_val = avg_result.get(\"std_ate_true_val\", np.nan)\n",
    "            mean_ate_bias_val = avg_result.get(\"mean_ate_bias_val\", np.nan)\n",
    "            std_ate_bias_val = avg_result.get(\"std_ate_bias_val\", np.nan)\n",
    "            mean_cate_mse_val = avg_result.get(\"mean_cate_mse_val\", np.nan)\n",
    "            std_cate_mse_val = avg_result.get(\"std_cate_mse_val\", np.nan)\n",
    "            mean_ate_bias_val = avg_result.get(\"mean_ate_bias_val\", np.nan)\n",
    "            std_ate_bias_val = avg_result.get(\"std_ate_bias_val\", np.nan)\n",
    "\n",
    "            runtime = avg_result.get(\"runtime\", np.nan)\n",
    "\n",
    "            records.append({\n",
    "                \"setup_name\": setup_name,\n",
    "                \"scenario_key\": scenario_key,\n",
    "                \"CATE_MSE\": f\"{mean_mse:.3f} ± {std_mse:.3f}\" if not pd.isna(mean_mse) else np.nan,\n",
    "                \"ATE_pred\": f\"{mean_ate_pred:.3f} ± {std_ate_pred:.3f}\" if not pd.isna(mean_ate_pred) else np.nan,\n",
    "                \"ATE_true\": f\"{mean_ate_true:.3f} ± {std_ate_true:.3f}\" if not pd.isna(mean_ate_true) else np.nan,\n",
    "                \"ATE_bias\": f\"{mean_ate_bias:.3f} ± {std_ate_bias:.3f}\" if not pd.isna(mean_ate_bias) else np.nan,\n",
    "                \n",
    "                \"CATE_MSE_val\": f\"{mean_cate_mse_val:.3f} ± {std_cate_mse_val:.3f}\" if not pd.isna(mean_cate_mse_val) else np.nan,\n",
    "                \"ATE_pred_val\": f\"{mean_ate_pred_val:.3f} ± {std_ate_pred_val:.3f}\" if not pd.isna(mean_ate_pred_val) else np.nan,\n",
    "                \"ATE_true_val\": f\"{mean_ate_true_val:.3f} ± {std_ate_true_val:.3f}\" if not pd.isna(mean_ate_true_val) else np.nan,\n",
    "                \"ATE_bias_val\": f\"{mean_ate_bias_val:.3f} ± {std_ate_bias_val:.3f}\" if not pd.isna(mean_ate_bias_val) else np.nan,\n",
    "                \"ATE_bias_val\": f\"{mean_ate_bias_val:.3f} ± {std_ate_bias_val:.3f}\" if not pd.isna(mean_ate_bias_val) else np.nan,\n",
    "                \"runtime [s]\": round(runtime) if not pd.isna(runtime) else np.nan\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd5e15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup_name</th>\n",
       "      <th>scenario_key</th>\n",
       "      <th>CATE_MSE</th>\n",
       "      <th>ATE_pred</th>\n",
       "      <th>ATE_true</th>\n",
       "      <th>ATE_bias</th>\n",
       "      <th>CATE_MSE_val</th>\n",
       "      <th>ATE_pred_val</th>\n",
       "      <th>ATE_true_val</th>\n",
       "      <th>ATE_bias_val</th>\n",
       "      <th>runtime [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twin</td>\n",
       "      <td>scenario_1</td>\n",
       "      <td>10864.104 ± 411.275</td>\n",
       "      <td>9.235 ± 4.103</td>\n",
       "      <td>5.038 ± 0.000</td>\n",
       "      <td>4.197 ± 4.103</td>\n",
       "      <td>11450.804 ± 442.565</td>\n",
       "      <td>9.163 ± 4.054</td>\n",
       "      <td>5.038 ± 0.000</td>\n",
       "      <td>4.125 ± 4.054</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>twin180</td>\n",
       "      <td>scenario_1</td>\n",
       "      <td>2444.692 ± 100.620</td>\n",
       "      <td>6.146 ± 2.539</td>\n",
       "      <td>2.260 ± 0.000</td>\n",
       "      <td>3.886 ± 2.539</td>\n",
       "      <td>2605.536 ± 114.053</td>\n",
       "      <td>5.996 ± 2.570</td>\n",
       "      <td>2.260 ± 0.000</td>\n",
       "      <td>3.736 ± 2.570</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twin30</td>\n",
       "      <td>scenario_1</td>\n",
       "      <td>75.075 ± 13.229</td>\n",
       "      <td>2.167 ± 1.962</td>\n",
       "      <td>0.328 ± 0.000</td>\n",
       "      <td>1.839 ± 1.962</td>\n",
       "      <td>79.151 ± 12.305</td>\n",
       "      <td>2.030 ± 1.962</td>\n",
       "      <td>0.328 ± 0.000</td>\n",
       "      <td>1.702 ± 1.962</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  setup_name scenario_key             CATE_MSE       ATE_pred       ATE_true  \\\n",
       "0       twin   scenario_1  10864.104 ± 411.275  9.235 ± 4.103  5.038 ± 0.000   \n",
       "1    twin180   scenario_1   2444.692 ± 100.620  6.146 ± 2.539  2.260 ± 0.000   \n",
       "2     twin30   scenario_1      75.075 ± 13.229  2.167 ± 1.962  0.328 ± 0.000   \n",
       "\n",
       "        ATE_bias         CATE_MSE_val   ATE_pred_val   ATE_true_val  \\\n",
       "0  4.197 ± 4.103  11450.804 ± 442.565  9.163 ± 4.054  5.038 ± 0.000   \n",
       "1  3.886 ± 2.539   2605.536 ± 114.053  5.996 ± 2.570  2.260 ± 0.000   \n",
       "2  1.839 ± 1.962      79.151 ± 12.305  2.030 ± 1.962  0.328 ± 0.000   \n",
       "\n",
       "    ATE_bias_val  runtime [s]  \n",
       "0  4.125 ± 4.054            7  \n",
       "1  3.736 ± 2.570            7  \n",
       "2  1.702 ± 1.962            7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = summarize_experiment_results(results_dict)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df04b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.664583082872483"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(75.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114ecc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.44382671274545"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2444.692)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc9fccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.2310126593808"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(10864.104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29144b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_survival_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
