{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scenario_data(h5_file_path, scenario_num):\n",
    "    key = f\"scenario_{scenario_num}/data\"\n",
    "    with pd.HDFStore(h5_file_path, mode='r') as store:\n",
    "        if key not in store:\n",
    "            return None  # Scenario not found\n",
    "        df = store[key]\n",
    "        metadata = store.get_storer(key).attrs.metadata\n",
    "    return {\"dataset\": df, \"metadata\": metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_files = [\n",
    "    \"../synthetic_data/RCT_0_5.h5\",\n",
    "    \"../synthetic_data/RCT_0_05.h5\",\n",
    "    \"../synthetic_data/e_X.h5\",\n",
    "    \"../synthetic_data/e_X_U.h5\",\n",
    "    \"../synthetic_data/e_X_no_overlap.h5\",\n",
    "    \"../synthetic_data/e_X_info_censor.h5\",\n",
    "    \"../synthetic_data/e_X_U_info_censor.h5\",\n",
    "    \"../synthetic_data/e_X_no_overlap_info_censor.h5\"\n",
    "]\n",
    "\n",
    "experiment_setups = {}\n",
    "\n",
    "for path in store_files:\n",
    "    base_name = os.path.splitext(os.path.basename(path))[0]  # e.g. RCT_0_5\n",
    "    scenario_dict = {}\n",
    "    # for scenario in range(1, 11):\n",
    "    for scenario in ['A', 'B', 'C', 'D', 'E']:\n",
    "        try:\n",
    "            result = load_scenario_data(path, scenario)\n",
    "            if result is not None:\n",
    "                scenario_dict[f\"scenario_{scenario}\"] = result\n",
    "        except Exception as e:\n",
    "            # Log or ignore as needed\n",
    "            continue\n",
    "    experiment_setups[base_name] = scenario_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>observed_time</th>\n",
       "      <th>event</th>\n",
       "      <th>W</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135488</td>\n",
       "      <td>0.887852</td>\n",
       "      <td>0.932606</td>\n",
       "      <td>0.445568</td>\n",
       "      <td>0.388236</td>\n",
       "      <td>0.151609</td>\n",
       "      <td>0.205535</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>0.061394</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>1.803019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.732630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.257596</td>\n",
       "      <td>0.657368</td>\n",
       "      <td>0.492617</td>\n",
       "      <td>0.964238</td>\n",
       "      <td>0.800984</td>\n",
       "      <td>0.597208</td>\n",
       "      <td>0.255785</td>\n",
       "      <td>0.228566</td>\n",
       "      <td>0.732630</td>\n",
       "      <td>0.732630</td>\n",
       "      <td>1.689546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.162856</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455205</td>\n",
       "      <td>0.801058</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>0.769458</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.370382</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.176016</td>\n",
       "      <td>0.162856</td>\n",
       "      <td>0.162856</td>\n",
       "      <td>1.256329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292809</td>\n",
       "      <td>0.610914</td>\n",
       "      <td>0.913027</td>\n",
       "      <td>0.300115</td>\n",
       "      <td>0.248599</td>\n",
       "      <td>0.038464</td>\n",
       "      <td>0.409829</td>\n",
       "      <td>0.381909</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>1.241777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.524607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666392</td>\n",
       "      <td>0.987533</td>\n",
       "      <td>0.468270</td>\n",
       "      <td>0.123287</td>\n",
       "      <td>0.916031</td>\n",
       "      <td>0.342961</td>\n",
       "      <td>0.791330</td>\n",
       "      <td>0.524607</td>\n",
       "      <td>1.121968</td>\n",
       "      <td>0.524607</td>\n",
       "      <td>1.516613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  observed_time  event  W        X1        X2        X3        X4  \\\n",
       "0   0       0.054267      1  0  0.135488  0.887852  0.932606  0.445568   \n",
       "1   1       0.732630      1  1  0.257596  0.657368  0.492617  0.964238   \n",
       "2   2       0.162856      1  1  0.455205  0.801058  0.041718  0.769458   \n",
       "3   3       0.050340      1  1  0.292809  0.610914  0.913027  0.300115   \n",
       "4   4       0.524607      1  0  0.666392  0.987533  0.468270  0.123287   \n",
       "\n",
       "         X5        U1        U2        T0        T1         T         C  \n",
       "0  0.388236  0.151609  0.205535  0.054267  0.061394  0.054267  1.803019  \n",
       "1  0.800984  0.597208  0.255785  0.228566  0.732630  0.732630  1.689546  \n",
       "2  0.003171  0.370382  0.223214  0.176016  0.162856  0.162856  1.256329  \n",
       "3  0.248599  0.038464  0.409829  0.381909  0.050340  0.050340  1.241777  \n",
       "4  0.916031  0.342961  0.791330  0.524607  1.121968  0.524607  1.516613  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_setups['RCT_0_5']['scenario_B']['dataset'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_idx0</th>\n",
       "      <th>random_idx1</th>\n",
       "      <th>random_idx2</th>\n",
       "      <th>random_idx3</th>\n",
       "      <th>random_idx4</th>\n",
       "      <th>random_idx5</th>\n",
       "      <th>random_idx6</th>\n",
       "      <th>random_idx7</th>\n",
       "      <th>random_idx8</th>\n",
       "      <th>random_idx9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47390</td>\n",
       "      <td>5618</td>\n",
       "      <td>14210</td>\n",
       "      <td>46970</td>\n",
       "      <td>4203</td>\n",
       "      <td>16369</td>\n",
       "      <td>24535</td>\n",
       "      <td>45204</td>\n",
       "      <td>45725</td>\n",
       "      <td>45885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38566</td>\n",
       "      <td>46218</td>\n",
       "      <td>39045</td>\n",
       "      <td>7253</td>\n",
       "      <td>22759</td>\n",
       "      <td>34401</td>\n",
       "      <td>28889</td>\n",
       "      <td>38471</td>\n",
       "      <td>45822</td>\n",
       "      <td>37471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32814</td>\n",
       "      <td>20226</td>\n",
       "      <td>40012</td>\n",
       "      <td>4854</td>\n",
       "      <td>27351</td>\n",
       "      <td>39165</td>\n",
       "      <td>25359</td>\n",
       "      <td>14516</td>\n",
       "      <td>25717</td>\n",
       "      <td>29860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41393</td>\n",
       "      <td>39492</td>\n",
       "      <td>27153</td>\n",
       "      <td>19041</td>\n",
       "      <td>33009</td>\n",
       "      <td>19822</td>\n",
       "      <td>21243</td>\n",
       "      <td>41228</td>\n",
       "      <td>955</td>\n",
       "      <td>23901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12564</td>\n",
       "      <td>17823</td>\n",
       "      <td>48976</td>\n",
       "      <td>18458</td>\n",
       "      <td>22756</td>\n",
       "      <td>28169</td>\n",
       "      <td>45851</td>\n",
       "      <td>36620</td>\n",
       "      <td>29824</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>15948</td>\n",
       "      <td>39245</td>\n",
       "      <td>30779</td>\n",
       "      <td>48178</td>\n",
       "      <td>45056</td>\n",
       "      <td>4892</td>\n",
       "      <td>528</td>\n",
       "      <td>7486</td>\n",
       "      <td>31042</td>\n",
       "      <td>38267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>11102</td>\n",
       "      <td>29624</td>\n",
       "      <td>40779</td>\n",
       "      <td>3136</td>\n",
       "      <td>45904</td>\n",
       "      <td>41903</td>\n",
       "      <td>45682</td>\n",
       "      <td>36621</td>\n",
       "      <td>33204</td>\n",
       "      <td>38070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>16338</td>\n",
       "      <td>8986</td>\n",
       "      <td>19293</td>\n",
       "      <td>35651</td>\n",
       "      <td>10172</td>\n",
       "      <td>17947</td>\n",
       "      <td>38843</td>\n",
       "      <td>18310</td>\n",
       "      <td>2765</td>\n",
       "      <td>12581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>32478</td>\n",
       "      <td>32134</td>\n",
       "      <td>11955</td>\n",
       "      <td>36939</td>\n",
       "      <td>33266</td>\n",
       "      <td>41932</td>\n",
       "      <td>43910</td>\n",
       "      <td>21691</td>\n",
       "      <td>40801</td>\n",
       "      <td>33527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>23102</td>\n",
       "      <td>2305</td>\n",
       "      <td>33545</td>\n",
       "      <td>20070</td>\n",
       "      <td>20726</td>\n",
       "      <td>1875</td>\n",
       "      <td>26988</td>\n",
       "      <td>24790</td>\n",
       "      <td>17795</td>\n",
       "      <td>39733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       random_idx0  random_idx1  random_idx2  random_idx3  random_idx4  \\\n",
       "idx                                                                      \n",
       "0            47390         5618        14210        46970         4203   \n",
       "1            38566        46218        39045         7253        22759   \n",
       "2            32814        20226        40012         4854        27351   \n",
       "3            41393        39492        27153        19041        33009   \n",
       "4            12564        17823        48976        18458        22756   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "49995        15948        39245        30779        48178        45056   \n",
       "49996        11102        29624        40779         3136        45904   \n",
       "49997        16338         8986        19293        35651        10172   \n",
       "49998        32478        32134        11955        36939        33266   \n",
       "49999        23102         2305        33545        20070        20726   \n",
       "\n",
       "       random_idx5  random_idx6  random_idx7  random_idx8  random_idx9  \n",
       "idx                                                                     \n",
       "0            16369        24535        45204        45725        45885  \n",
       "1            34401        28889        38471        45822        37471  \n",
       "2            39165        25359        14516        25717        29860  \n",
       "3            19822        21243        41228          955        23901  \n",
       "4            28169        45851        36620        29824        12711  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "49995         4892          528         7486        31042        38267  \n",
       "49996        41903        45682        36621        33204        38070  \n",
       "49997        17947        38843        18310         2765        12581  \n",
       "49998        41932        43910        21691        40801        33527  \n",
       "49999         1875        26988        24790        17795        39733  \n",
       "\n",
       "[50000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_repeat_setups = pd.read_csv(\"../synthetic_data/idx_split.csv\").set_index(\"idx\")\n",
    "experiment_repeat_setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats_to_include = 10  # max 10\n",
    "num_training_data_points = 500 # max 45000\n",
    "test_size = 5000\n",
    "imputation_method = 'Pseudo_obs' # 'Pseudo_obs', 'Margin', 'IPCW-T'\n",
    "meta_learner_type = 'dr_learner'\n",
    "load_imputed_values = True\n",
    "imputed_times_path = f\"../synthetic_data/imputed_times_lookup.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pickle_path = f\"results/{meta_learner_type}_{imputation_method}_num_repeats_{num_repeats_to_include}_train_size_{num_training_data_points}.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of \"notebooks\" to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from models_causal_impute.meta_learners import T_Learner, S_Learner, X_Learner, DR_Learner\n",
    "from models_causal_impute.survival_eval_impute import SurvivalEvalImputer\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_split(dataset_df, experiment_repeat_setups, random_idx_col_list, num_training_data_points=5000, test_size=5000):\n",
    "    split_results = {}\n",
    "\n",
    "    for rand_idx in random_idx_col_list:\n",
    "        random_idx = experiment_repeat_setups[rand_idx].values\n",
    "        test_ids = random_idx[-test_size:]\n",
    "        train_ids = random_idx[:min(num_training_data_points, len(random_idx) - test_size)]\n",
    "\n",
    "        X_cols = [c for c in dataset_df.columns if c.startswith(\"X\") and c[1:].isdigit()]\n",
    "        \n",
    "        train_df = dataset_df[dataset_df['id'].isin(train_ids)]\n",
    "        test_df = dataset_df[dataset_df['id'].isin(test_ids)]\n",
    "\n",
    "        X_train = train_df[X_cols].to_numpy()\n",
    "        W_train = train_df[\"W\"].to_numpy()\n",
    "        Y_train = train_df[[\"observed_time\", \"event\"]].to_numpy()\n",
    "\n",
    "        X_test = test_df[X_cols].to_numpy()\n",
    "        W_test = test_df[\"W\"].to_numpy()\n",
    "        Y_test = test_df[[\"observed_time\", \"event\"]].to_numpy()\n",
    "\n",
    "        cate_test_true = (test_df[\"T1\"] - test_df[\"T0\"]).to_numpy()\n",
    "\n",
    "        split_results[rand_idx] = (X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true)\n",
    "\n",
    "    return split_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx_col_list = experiment_repeat_setups.columns.to_list()[:num_repeats_to_include]\n",
    "\n",
    "print(\"Output results path:\", output_pickle_path)\n",
    "\n",
    "# base_regressors = ['ridge', 'lasso', 'rf', 'gbr', 'xgb']\n",
    "base_regressors = ['lasso', 'rf', 'xgb']\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for setup_name, setup_dict in tqdm(experiment_setups.items(), desc=\"Experiment Setups\"):\n",
    "\n",
    "    results_dict[setup_name] = {}\n",
    "\n",
    "    for scenario_key in tqdm(setup_dict, desc=f\"{setup_name} Scenarios\"):\n",
    "        dataset_df = setup_dict[scenario_key][\"dataset\"]\n",
    "        split_dict = prepare_data_split(dataset_df, experiment_repeat_setups, random_idx_col_list, num_training_data_points, test_size)\n",
    "\n",
    "        # Initialize results dictionary for this setup and scenario\n",
    "        results_dict[setup_name][scenario_key] = {}\n",
    "\n",
    "        # For each base model, we will run the TLearner\n",
    "        for base_model in tqdm(base_regressors, desc=\"Base Models\", leave=False):\n",
    "            # print(f\"Running {base_model} for {setup_name} - {scenario_key}\")\n",
    "            \n",
    "            # Store placeholder for later population\n",
    "            results_dict[setup_name][scenario_key][base_model] = {}\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            for rand_idx in random_idx_col_list:\n",
    "                X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true = split_dict[rand_idx]\n",
    "\n",
    "                Y_train_imputed, Y_test_imputed = None, None\n",
    "                if load_imputed_values:\n",
    "                    # Load imputed values\n",
    "                    with open(imputed_times_path, \"rb\") as f:\n",
    "                        imputed_times = pickle.load(f)\n",
    "\n",
    "                    # Get imputed values for the current random index\n",
    "                    imputed_results = imputed_times.get(imputation_method, {}).get(setup_name, {}).get(scenario_key, {}).get(num_training_data_points, {}).get(rand_idx, {})\n",
    "                    Y_train_imputed = imputed_results.get(\"Y_train_imputed\", None)\n",
    "                    Y_test_imputed = imputed_results.get(\"Y_test_imputed\", None)\n",
    "                \n",
    "                # If imputed values are not loaded, use the original Y_train and Y_test\n",
    "                if Y_train_imputed is None:\n",
    "                    # impute the missing values\n",
    "                    print(f\"[Train] Imputing missing values for {setup_name} - {scenario_key} - {base_model} - {rand_idx}\")\n",
    "                    survival_imputer = SurvivalEvalImputer(imputation_method=imputation_method, verbose=False)\n",
    "                    Y_train_imputed, Y_test_imputed = survival_imputer.fit_transform(Y_train, Y_test)\n",
    "                \n",
    "                if Y_test_imputed is None:\n",
    "                    # impute the missing values\n",
    "                    print(f\"[Test] Imputing missing values for {setup_name} - {scenario_key} - {base_model} - {rand_idx}\")\n",
    "                    survival_imputer = SurvivalEvalImputer(imputation_method=imputation_method, verbose=False)\n",
    "                    _, Y_test_imputed = survival_imputer.fit_transform(Y_train, Y_test, impute_train=False)\n",
    "                \n",
    "                if meta_learner_type == 't_learner':\n",
    "                    learner = T_Learner(base_model_name=base_model)\n",
    "                elif meta_learner_type == 's_learner':\n",
    "                    learner = S_Learner(base_model_name=base_model)\n",
    "                elif meta_learner_type == 'x_learner':\n",
    "                    learner = X_Learner(base_model_name=base_model)\n",
    "                elif meta_learner_type == 'dr_learner':\n",
    "                    learner = DR_Learner(base_model_name=base_model)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown meta-learner type: {meta_learner_type}\")\n",
    "                \n",
    "                learner.fit(X_train, W_train, Y_train_imputed)\n",
    "                mse_test, cate_test_pred, ate_test_pred = learner.evaluate(X_test, cate_test_true, W_test)\n",
    "\n",
    "                # Evaluate base survival models on test data\n",
    "                base_model_eval = learner.evaluate_test(X_test, Y_test_imputed, W_test)\n",
    "\n",
    "                # Save results\n",
    "                results_dict[setup_name][scenario_key][base_model][rand_idx] = {\n",
    "                    \"cate_true\": cate_test_true,\n",
    "                    \"cate_pred\": cate_test_pred,\n",
    "                    \"ate_true\": cate_test_true.mean(),\n",
    "                    \"ate_pred\": ate_test_pred.mean_point,\n",
    "                    \"cate_mse\": mse_test,\n",
    "                    \"ate_bias\": ate_test_pred.mean_point - cate_test_true.mean(),\n",
    "                    \"base_model_eval\": base_model_eval, # Store base model evaluation results\n",
    "                    \"ate_interval\": ate_test_pred.conf_int_mean(),\n",
    "                    \"ate_statistics\": ate_test_pred\n",
    "                }\n",
    "\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Save results to the setup dictionary\n",
    "            avg = results_dict[setup_name][scenario_key][base_model]\n",
    "            base_model_eval_performance = {\n",
    "                                            base_model_k: \n",
    "                                            {\n",
    "                                                f\"{stat}_{metric_j}\": func([\n",
    "                                                    avg[i]['base_model_eval'][base_model_k][metric_j] for i in random_idx_col_list\n",
    "                                                    if i in avg\n",
    "                                                ])\n",
    "                                                for metric_j in metric_j_dict\n",
    "                                                for stat, func in zip(['mean', 'std'], [np.nanmean, np.nanstd])\n",
    "                                            }\n",
    "                                            for base_model_k, metric_j_dict in avg[list(avg.keys())[0]]['base_model_eval'].items()\n",
    "                                        }\n",
    "\n",
    "            results_dict[setup_name][scenario_key][base_model][\"average\"] = {\n",
    "                    \"mean_cate_mse\": np.mean([avg[i][\"cate_mse\"] for i in random_idx_col_list]),\n",
    "                    \"std_cate_mse\": np.std([avg[i][\"cate_mse\"] for i in random_idx_col_list]),\n",
    "                    \"mean_ate_pred\": np.mean([avg[i][\"ate_pred\"] for i in random_idx_col_list]),\n",
    "                    \"std_ate_pred\": np.std([avg[i][\"ate_pred\"] for i in random_idx_col_list]),\n",
    "                    \"mean_ate_true\": np.mean([avg[i][\"ate_true\"] for i in random_idx_col_list]),\n",
    "                    \"std_ate_true\": np.std([avg[i][\"ate_true\"] for i in random_idx_col_list]),\n",
    "                    \"mean_ate_bias\": np.mean([avg[i][\"ate_bias\"] for i in random_idx_col_list]),\n",
    "                    \"std_ate_bias\": np.std([avg[i][\"ate_bias\"] for i in random_idx_col_list]),\n",
    "                    \"runtime\": (end_time - start_time) / len(random_idx_col_list),\n",
    "                    \"base_model_eval\": base_model_eval_performance\n",
    "                }\n",
    "\n",
    "            # Save progress to disk\n",
    "            # with open(output_pickle_path, \"wb\") as f:\n",
    "                # pickle.dump(results_dict, f)\n",
    "            \n",
    "            # break\n",
    "        break\n",
    "    break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RCT_0_5': {'scenario_1': {'lasso': {'random_idx0': {'cate_true': array([ 0.01964673,  0.67548137,  0.01256466, ..., -0.08345062,\n",
       "             0.20826006, -0.22013693]),\n",
       "     'cate_pred': array([0.17841884, 0.17841884, 0.17841884, ..., 0.17841884, 0.17841884,\n",
       "            0.17841884]),\n",
       "     'ate_true': 0.12915102003284332,\n",
       "     'ate_pred': 0.17841883602193148,\n",
       "     'cate_mse': 0.6984174458687489,\n",
       "     'ate_bias': 0.049267815989088165,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.3673316102542654,\n",
       "       'r2': -1.2451456597186162e+32},\n",
       "      'propensity': {'auc': 0.4906432083995214, 'f1': 0.6746189529489728}},\n",
       "     'ate_interval': (0.08042516950731494, 0.276412502536548),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57c7d4d910>},\n",
       "    'random_idx1': {'cate_true': array([ 0.04373459, -0.01348651, -0.12558549, ...,  2.88443699,\n",
       "            -0.03312028,  0.24602149]),\n",
       "     'cate_pred': array([0.0306718, 0.0306718, 0.0306718, ..., 0.0306718, 0.0306718,\n",
       "            0.0306718]),\n",
       "     'ate_true': 0.12449698781077848,\n",
       "     'ate_pred': 0.030671802904516154,\n",
       "     'cate_mse': 0.7306534300243928,\n",
       "     'ate_bias': -0.09382518490626232,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.324736897886753,\n",
       "       'r2': 0.0},\n",
       "      'propensity': {'auc': 0.500213600034176, 'f1': 0.6372868488128726}},\n",
       "     'ate_interval': (-0.04154533874530267, 0.10288894455433496),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57cc8bb700>},\n",
       "    'random_idx2': {'cate_true': array([-0.13083455, -0.25443191,  0.22322109, ..., -0.04042443,\n",
       "             0.68333127, -0.12309126]),\n",
       "     'cate_pred': array([0.20979724, 0.20979724, 0.20979724, ..., 0.20979724, 0.20979724,\n",
       "            0.20979724]),\n",
       "     'ate_true': 0.11320535412052017,\n",
       "     'ate_pred': 0.20979724010257664,\n",
       "     'cate_mse': 0.5950801828712796,\n",
       "     'ate_bias': 0.09659188598205647,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.3449346313420123,\n",
       "       'r2': -7.01357201466741e+31},\n",
       "      'propensity': {'auc': 0.49797171707927257, 'f1': 0.5062853971078812}},\n",
       "     'ate_interval': (0.1254783133860194, 0.2941161668191339),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57ce10a160>},\n",
       "    'random_idx3': {'cate_true': array([-0.13083455, -0.29553616,  0.61790216, ..., -0.03312028,\n",
       "             1.12117897, -0.21827961]),\n",
       "     'cate_pred': array([0.09984718, 0.09984718, 0.09984718, ..., 0.09984718, 0.09984718,\n",
       "            0.09984718]),\n",
       "     'ate_true': 0.13422576870599365,\n",
       "     'ate_pred': 0.09984717775555758,\n",
       "     'cate_mse': 0.7035932841876302,\n",
       "     'ate_bias': -0.034378590950436064,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.299540599432409,\n",
       "       'r2': -3.9862122828720253e+31},\n",
       "      'propensity': {'auc': 0.5019466193121854, 'f1': 0.0}},\n",
       "     'ate_interval': (-1494.6866538670354, 1494.886348222546),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57c6e5cd00>},\n",
       "    'random_idx4': {'cate_true': array([ 0.0071266 ,  0.42334943,  0.11885308, ...,  1.40263868,\n",
       "            -0.44599299,  0.43901341]),\n",
       "     'cate_pred': array([0.07939853, 0.07939853, 0.07939853, ..., 0.07939853, 0.07939853,\n",
       "            0.07939853]),\n",
       "     'ate_true': 0.1454709648166056,\n",
       "     'ate_pred': 0.07939853296850362,\n",
       "     'cate_mse': 0.8317431971653446,\n",
       "     'ate_bias': -0.06607243184810198,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.3608646448304422,\n",
       "       'r2': -7.899061166272483e+30},\n",
       "      'propensity': {'auc': 0.49120025359757963, 'f1': 0.537755424548223}},\n",
       "     'ate_interval': (-0.02329368835536623, 0.18209075429237345),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57cc266880>},\n",
       "    'random_idx5': {'cate_true': array([ 0.0071266 , -0.33156902, -0.13083455, ..., -0.08345062,\n",
       "            -0.22013693, -0.12309126]),\n",
       "     'cate_pred': array([0.08227591, 0.08227591, 0.08227591, ..., 0.08227591, 0.08227591,\n",
       "            0.08227591]),\n",
       "     'ate_true': 0.1150924596635593,\n",
       "     'ate_pred': 0.0822759134061561,\n",
       "     'cate_mse': 0.7357499110188405,\n",
       "     'ate_bias': -0.0328165462574032,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.31998791589432257,\n",
       "       'r2': -1.878052257477091e+32},\n",
       "      'propensity': {'auc': 0.5000713600456704, 'f1': 0.0}},\n",
       "     'ate_interval': (0.003240817881037805, 0.16131100893127437),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57cc7a4490>},\n",
       "    'random_idx6': {'cate_true': array([ 0.13581265,  0.01859975, -0.01528941, ...,  0.1718276 ,\n",
       "            -0.2025199 , -0.23328487]),\n",
       "     'cate_pred': array([0.09522598, 0.09522598, 0.09522598, ..., 0.09522598, 0.09522598,\n",
       "            0.09522598]),\n",
       "     'ate_true': 0.10842338016300965,\n",
       "     'ate_pred': 0.09522597737063233,\n",
       "     'cate_mse': 0.6436969159210374,\n",
       "     'ate_bias': -0.013197402792377314,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.3040782283647896,\n",
       "       'r2': -3.885936653733008e+31},\n",
       "      'propensity': {'auc': 0.4958038890823159, 'f1': 0.6763732627399074}},\n",
       "     'ate_interval': (0.028698684048450496, 0.16175327069281414),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57c6a6c370>},\n",
       "    'random_idx7': {'cate_true': array([-0.09800848,  0.01964673,  0.11885308, ...,  1.12117897,\n",
       "            -0.08345062,  0.05523445]),\n",
       "     'cate_pred': array([0.10761433, 0.10761433, 0.10761433, ..., 0.10761433, 0.10761433,\n",
       "            0.10761433]),\n",
       "     'ate_true': 0.13962732961458268,\n",
       "     'ate_pred': 0.10761433454111016,\n",
       "     'cate_mse': 0.617296541721836,\n",
       "     'ate_bias': -0.03201299507347252,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.3371135247990268,\n",
       "       'r2': -5.929704852406143e+31},\n",
       "      'propensity': {'auc': 0.5027483204397313, 'f1': 0.5120211447098518}},\n",
       "     'ate_interval': (0.02805698590573734, 0.18717168317648297),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57cc871cd0>},\n",
       "    'random_idx8': {'cate_true': array([ 1.16187434,  0.14004801,  0.01956567, ..., -3.04577956,\n",
       "             0.05523445, -0.4338563 ]),\n",
       "     'cate_pred': array([0.04195602, 0.04195602, 0.04195602, ..., 0.04195602, 0.04195602,\n",
       "            0.04195602]),\n",
       "     'ate_true': 0.12974416208389994,\n",
       "     'ate_pred': 0.04195602248839332,\n",
       "     'cate_mse': 0.6350718584909588,\n",
       "     'ate_bias': -0.08778813959550662,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.34645702454907357,\n",
       "       'r2': -1.2351861855347442e+31},\n",
       "      'propensity': {'auc': 0.4989965919333033, 'f1': 0.6194005186141478}},\n",
       "     'ate_interval': (-0.054494253644020704, 0.13840629862080733),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57cc54c7c0>},\n",
       "    'random_idx9': {'cate_true': array([ 0.03760702,  0.2885753 ,  1.12633537, ...,  0.71218822,\n",
       "             0.45455053, -0.09461645]),\n",
       "     'cate_pred': array([0.11772394, 0.11772394, 0.11772394, ..., 0.11772394, 0.11772394,\n",
       "            0.11772394]),\n",
       "     'ate_true': 0.12530238395151086,\n",
       "     'ate_pred': 0.11772393549642325,\n",
       "     'cate_mse': 0.7121521009209281,\n",
       "     'ate_bias': -0.007578448455087608,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.3194498208612635,\n",
       "       'r2': -1.0561765717114293e+32},\n",
       "      'propensity': {'auc': 0.4973977993915445, 'f1': 0.6562751948400968}},\n",
       "     'ate_interval': (0.05173940195258596, 0.18370846904026053),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57c7637610>},\n",
       "    'average': {'mean_cate_mse': 0.6903454868190997,\n",
       "     'std_cate_mse': 0.0663616480066591,\n",
       "     'mean_ate_pred': 0.10429297730558007,\n",
       "     'std_ate_pred': 0.05227776562719439,\n",
       "     'mean_ate_true': 0.12647398109633037,\n",
       "     'std_ate_true': 0.011173842796182968,\n",
       "     'mean_ate_bias': -0.022181003790750296,\n",
       "     'std_ate_bias': 0.0558820894955938,\n",
       "     'runtime': 101.54969851970672,\n",
       "     'base_model_eval': {'model_regression': {'mean_mae': 0.3324494898214358,\n",
       "       'std_mae': 0.021609526153360127,\n",
       "       'mean_r2': -6.4634262994911955e+31,\n",
       "       'std_r2': 5.648278675979952e+31},\n",
       "      'propensity': {'mean_auc': 0.49769933593153004,\n",
       "       'std_auc': 0.003910848982688113,\n",
       "       'mean_f1': 0.4820016744321953,\n",
       "       'std_f1': 0.24849456628876831}}}},\n",
       "   'rf': {'random_idx0': {'cate_true': array([ 0.01964673,  0.67548137,  0.01256466, ..., -0.08345062,\n",
       "             0.20826006, -0.22013693]),\n",
       "     'cate_pred': array([ 0.1828918 , -0.31131102,  0.0027594 , ...,  0.32476247,\n",
       "             1.11602982, -0.09120585]),\n",
       "     'ate_true': 0.12915102003284332,\n",
       "     'ate_pred': 0.17526261968816514,\n",
       "     'cate_mse': 0.8996284497239958,\n",
       "     'ate_bias': 0.04611159965532183,\n",
       "     'base_model_eval': {'model_regression': {'mae': 0.3650921696005974,\n",
       "       'r2': -2.34938035192991},\n",
       "      'propensity': {'auc': 0.4906432083995214, 'f1': 0.6746189529489728}},\n",
       "     'ate_interval': (-1.0124614331400967, 1.3629866725164268),\n",
       "     'ate_statistics': <econml.inference._inference.PopulationSummaryResults at 0x7a57cc1dfaf0>}}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_experiment_results(results_dict):\n",
    "    records = []\n",
    "\n",
    "    for setup_name, setup_dict in results_dict.items():\n",
    "        for scenario_key in setup_dict:\n",
    "            row = {\n",
    "                (\"setup_name\", \"\"): setup_name,\n",
    "                (\"scenario_key\", \"\"): scenario_key\n",
    "            }\n",
    "\n",
    "            for base_model in setup_dict[scenario_key]:\n",
    "                avg_result = setup_dict[scenario_key].get(base_model, {}).get(\"average\", {})\n",
    "                mean_mse = avg_result.get(\"mean_cate_mse\", np.nan)\n",
    "                std_mse = avg_result.get(\"std_cate_mse\", np.nan)\n",
    "                mean_ate_pred = avg_result.get(\"mean_ate_pred\", np.nan)\n",
    "                std_ate_pred = avg_result.get(\"std_ate_pred\", np.nan)\n",
    "                mean_ate_true = avg_result.get(\"mean_ate_true\", np.nan)\n",
    "                std_ate_true = avg_result.get(\"std_ate_true\", np.nan)\n",
    "                mean_ate_bias = avg_result.get(\"mean_ate_bias\", np.nan)\n",
    "                std_ate_bias = avg_result.get(\"std_ate_bias\", np.nan)\n",
    "                runtime = avg_result.get(\"runtime\", np.nan)\n",
    "\n",
    "                row[(base_model, \"CATE_MSE\")] = f\"{mean_mse:.3f} ± {std_mse:.3f}\" if not pd.isna(mean_mse) else np.nan\n",
    "                row[(base_model, \"ATE_pred\")] = f\"{mean_ate_pred:.3f} ± {std_ate_pred:.3f}\" if not pd.isna(mean_ate_pred) else np.nan\n",
    "                row[(base_model, \"ATE_true\")] = f\"{mean_ate_true:.3f} ± {std_ate_true:.3f}\" if not pd.isna(mean_ate_true) else np.nan\n",
    "                row[(base_model, \"ATE_bias\")] = f\"{mean_ate_bias:.3f} ± {std_ate_bias:.3f}\" if not pd.isna(mean_ate_bias) else np.nan\n",
    "                row[(base_model, \"runtime [s]\")] = round(runtime) if not pd.isna(runtime) else np.nan\n",
    "\n",
    "            records.append(row)\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Learner Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>setup_name</th>\n",
       "      <th>scenario_key</th>\n",
       "      <th colspan=\"5\" halign=\"left\">lasso</th>\n",
       "      <th colspan=\"5\" halign=\"left\">rf</th>\n",
       "      <th colspan=\"5\" halign=\"left\">xgb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CATE_MSE</th>\n",
       "      <th>ATE_pred</th>\n",
       "      <th>ATE_true</th>\n",
       "      <th>ATE_bias</th>\n",
       "      <th>runtime [s]</th>\n",
       "      <th>CATE_MSE</th>\n",
       "      <th>ATE_pred</th>\n",
       "      <th>ATE_true</th>\n",
       "      <th>ATE_bias</th>\n",
       "      <th>runtime [s]</th>\n",
       "      <th>CATE_MSE</th>\n",
       "      <th>ATE_pred</th>\n",
       "      <th>ATE_true</th>\n",
       "      <th>ATE_bias</th>\n",
       "      <th>runtime [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RCT_0_5</td>\n",
       "      <td>scenario_1</td>\n",
       "      <td>0.690 ± 0.066</td>\n",
       "      <td>0.104 ± 0.052</td>\n",
       "      <td>0.126 ± 0.011</td>\n",
       "      <td>-0.022 ± 0.056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851 ± 0.135</td>\n",
       "      <td>0.111 ± 0.065</td>\n",
       "      <td>0.126 ± 0.011</td>\n",
       "      <td>-0.015 ± 0.068</td>\n",
       "      <td>1</td>\n",
       "      <td>1.365 ± 0.824</td>\n",
       "      <td>0.138 ± 0.061</td>\n",
       "      <td>0.126 ± 0.011</td>\n",
       "      <td>0.012 ± 0.061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  setup_name scenario_key          lasso                                \\\n",
       "                                CATE_MSE       ATE_pred       ATE_true   \n",
       "0    RCT_0_5   scenario_1  0.690 ± 0.066  0.104 ± 0.052  0.126 ± 0.011   \n",
       "\n",
       "                                          rf                                \\\n",
       "         ATE_bias runtime [s]       CATE_MSE       ATE_pred       ATE_true   \n",
       "0  -0.022 ± 0.056           1  0.851 ± 0.135  0.111 ± 0.065  0.126 ± 0.011   \n",
       "\n",
       "                                         xgb                                \\\n",
       "         ATE_bias runtime [s]       CATE_MSE       ATE_pred       ATE_true   \n",
       "0  -0.015 ± 0.068           1  1.365 ± 0.824  0.138 ± 0.061  0.126 ± 0.011   \n",
       "\n",
       "                              \n",
       "        ATE_bias runtime [s]  \n",
       "0  0.012 ± 0.061           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"T-Learner Results\")\n",
    "summary_df = summarize_experiment_results(results_dict)\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_survival_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
